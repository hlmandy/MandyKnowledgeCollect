## 附录：Logistics 回归

> 陈强 计量经济学
>
> kleinbaum2010 Kleinbaum, D. G.,  Klein, M. (2010). Logistic Regression. Statistics for Biology and Health

由于逻辑分布的 cdf 有解析表达式(而标准正态没有), 故计算 Logit 比 Probit 更为方便。
对于此非线性模型, 进行 MLE 估计。
以 Logit 模型为例。第 $i$ 个观测数据的概率密度为
$$
f\left(y_{i} \mid x_{i}, \boldsymbol{\beta}\right)=\left\{\begin{array}{l}
\Lambda\left(x_{i}^{\prime} \boldsymbol{\beta}\right), \text { 若 } y_{i}=1 \\
1-\Lambda\left(x_{i}^{\prime} \boldsymbol{\beta}\right), \text { 若 } y_{i}=0
\end{array}\right.
$$
将其更紧凑地写为
$$
f\left(y_{i} \mid x_{i}, \boldsymbol{\beta}\right)=\left[\Lambda\left(x_{i}^{\prime} \boldsymbol{\beta}\right)\right]^{y_{i}}\left[1-\Lambda\left(x_{i}^{\prime} \boldsymbol{\beta}\right)\right]^{1-y_{i}}
$$
取对数可得
$$
\ln f\left(y_{i} \mid x_{i}, \boldsymbol{\beta}\right)=y_{i} \ln \left[\Lambda\left(x_{i}^{\prime} \boldsymbol{\beta}\right)\right]+\left(1-y_{i}\right) \ln \left[1-\Lambda\left(\boldsymbol{x}_{\boldsymbol{i}}^{\prime} \boldsymbol{\beta}\right)\right]
$$
假设样本中的个体相互独立, 则整个样本的对数似然函数为
$$
\ln L(\boldsymbol{\beta} \mid \boldsymbol{y}, \boldsymbol{x})=\sum_{i=1}^{n} y_{i} \ln \left[\Lambda\left(\boldsymbol{x}_{\boldsymbol{i}}^{\prime} \boldsymbol{\beta}\right)\right]+\sum_{i=1}^{n}\left(1-y_{i}\right) \ln \left[1-\Lambda\left(\boldsymbol{x}_{\boldsymbol{i}}^{\prime} \boldsymbol{\beta}\right)\right]
$$
在此非线性模型中, 估计量 $\hat{\boldsymbol{\beta}}_{\mathrm{MLE}}$ 并非边际效应(marginal effects)。 以 Probit 为例,
$$
\frac{\partial \mathrm{P}(y=1 \mid \boldsymbol{x})}{\partial x_{k}}=\frac{\partial \mathrm{P}(y=1 \mid \boldsymbol{x})}{\partial\left(x^{\prime} \boldsymbol{\beta}\right)} \cdot \frac{\partial\left(x^{\prime} \boldsymbol{\beta}\right)}{\partial x_{k}}=\phi\left(x^{\prime} \boldsymbol{\beta}\right) \cdot \beta_{k}
$$
对于 Logit 模型, 记 $p \equiv \mathrm{P}(y=1 \mid \boldsymbol{x})$, 则 $1-p=\mathrm{P}(y=0 \mid \boldsymbol{x})$ 。
由于 $p=\frac{\exp \left(\boldsymbol{x}^{\prime} \boldsymbol{\beta}\right)}{1+\exp \left(\boldsymbol{x}^{\prime} \boldsymbol{\beta}\right)}, \quad 1-p=\frac{1}{1+\exp \left(\boldsymbol{x}^{\prime} \boldsymbol{\beta}\right)}$, 故
$$
\begin{aligned}
&\frac{p}{1-p}=\exp \left(\boldsymbol{x}^{\prime} \boldsymbol{\beta}\right) \\
&\ln \left(\frac{p}{1-p}\right)=\boldsymbol{x}^{\prime} \boldsymbol{\beta}
\end{aligned}
$$
$p /(1-p)$ 称为 “几率比” (odds ratio)或 “相对风险” (relative risk)。



【例】假设在检验药物疗效的随机实验中， “ $y=1$ ”表示 “生”, “ $y=0$ ”表示 “死”; 则几率比为 2 意味着存活的概率是死亡概率 的两倍。
$\hat{\beta}_{j}$ 表示解释变量 $x_{j}$ 增加一个微小量引起 “对数几率比” (log-odds ratio)的边际变化。
也可视 $\hat{\beta}_{j}$ 为半弹性, 即 $x_{j}$ 增加一单位引起几率比的变化百分比。 比如, $\hat{\beta}_{j}=0.12$, 意味着 $x_{j}$ 增加一单位引起几率比增加 $12 \%$ 。
另一解释: 假设 $x_{j}$ 增加一单位, 从 $x_{j}$ 变为 $x_{j}+1$, 记 $p$ 的新值为 $p^{*}$, 则新几率比与原先几率比的比率可写为:
$$
\frac{\frac{p^{*}}{1-p^{*}}}{\frac{p}{1-p}}=\frac{\exp \left[\beta_{1}+\beta_{2} x_{2}+\cdots+\beta_{j}\left(x_{j}+1\right)+\cdots+\beta_{K} x_{K}\right]}{\exp \left(\beta_{1}+\beta_{2} x_{2}+\cdots+\beta_{j} x_{j}+\cdots+\beta_{K} x_{K}\right)}=\exp \left(\beta_{j}\right)
$$
有些研究者偏好计算 $\exp \left(\hat{\beta}_{j}\right)$, 它表示解释变量 $x_{j}$ 增加一单位引 起几率比的变化倍数。
比如, $\hat{\beta}_{j}=0.12$, 则 $\exp \left(\hat{\beta}_{j}\right)=e^{0.12}=1.13$, 故当 $x_{j}$ 增加一单位时, 新几率比是原先几率比的 $1.13$ 倍, 或增加 $13 \%$, 因为 $\exp \left(\hat{\beta}_{j}\right)-1=1.13-1=0.13$ 。
基于此, Stata 称 $\exp \left(\hat{\beta}_{j}\right)$ 为几率比(odds ratio)。



### 如何衡量二值模型的拟合优度呢?

由于不存在平方和分解公式, 无法计算 $R^{2}$ 。
Stata 仍然汇报一个 “准 $R^{2 \text { ” }}$ (Pseudo $\mathrm{R}^{2}$ ), 由 McFadden (1974) 所提出:
$$
\text { 准 } R^{2} \equiv \frac{\ln L_{0}-\ln L_{1}}{\ln L_{0}}
$$
$\ln L_{1}$ 为原模型的对数似然函数之最大值, 而 $\ln L_{0}$ 为以常数项为唯 一解释变量的对数似然函数之最大值。
由于 $y$ 为离散的两点分布, 似然函数的最大可能值为 1 , 故对数 似然函数的最大可能值为 0 , 记为 $\ln L_{\max }$ 。由于 $0 \geq \ln L_{1} \geq \ln L_{0}$, 故
准 $R^{2}$ 可写为 $\frac{\ln L_{1}-\ln L_{0}}{\ln L_{\text {max }}-\ln L_{0}}$ 。

![image-20220409112025652](https://hl-pic.oss-cn-hangzhou.aliyuncs.com/image-20220409112025652-16513109119661.png)

图 $11.2$ 准 $R^{2}$ 的计算

判断拟合优度的另一方法是计算“正确预测的百分比”(percent correctly predicted)。

如果发生概率的预测值 *y*ˆ $\ge$ 0.5，则认为其预测 *y* =1；反之，则认为其预测*y* = 0。

将预测值与实际值(样本数据)进行比较，就能计算正确预测的百分比。

