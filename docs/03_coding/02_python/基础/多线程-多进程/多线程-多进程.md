# 多线程/多进程

## 目录

-   [multiprocess使用心得：](#multiprocess使用心得)

> 📌python 因为有线程锁，所以没有多线程，只有多进程

[python并行计算（完结篇）：并行方法总结 - 知乎](python并行计算（完结篇）：并行方法总结%20-%20知乎.md - 知乎/python并行计算（完结篇）：并行方法总结 - 知乎.md> "python并行计算（完结篇）：并行方法总结 - 知乎")

[python并行计算（上）：multiprocessing、multiprocess模块 - 知乎](python并行计算（上）：multiprocessing、multiprocess模块%20-%20知乎.md - 知乎.md> "python并行计算（上）：multiprocessing、multiprocess模块 - 知乎")

[python并行计算（下）：multiprocessing模块实例 - 知乎](python并行计算（下）：multiprocessing模块实例%20-%20知乎.md - 知乎.md> "python并行计算（下）：multiprocessing模块实例 - 知乎")

[pandas groupby apply 并行处理](pandas%20groupby%20apply%20并行处理.md groupby apply 并行处理/pandas groupby apply 并行处理.md> "pandas groupby apply 并行处理")

[Pandas groupby加速处理数据问题\_pd.groupby 运行速度-CSDN博客](https://blog.csdn.net/Pual_wang/article/details/106523653 "Pandas groupby加速处理数据问题_pd.groupby 运行速度-CSDN博客")

## multiprocess使用心得：

最好先把 pd.Dataframe group by之后的数据分组，且按照计算机process的个数分好组，再调用multiprocess。否则，当任务太多之后，multiprocess不一定能分配成功。

> 以下code by黄小猫，参考：[python并行计算（下）：multiprocessing模块实例 - 知乎](python并行计算（下）：multiprocessing模块实例%20-%20知乎.md - 知乎.md> "python并行计算（下）：multiprocessing模块实例 - 知乎")

```python
## 以下的代码既可以单线程也可以
def fun(args):
    if is_multi_process:
        (flts, process_idx, conn, t0) = args
    else:
        (flts) = args
    res = []
    for (keys, flt) in flts:
        ## 按group by进行处理，得到_result，假设为_tmp_dict,X_train_df,y_train
        res.append((_tmp_dict,X_train_df,y_train))
        
    if is_multi_process:
        t = time.time() - t0
        conn.send('data process of %d: finished@%.2fs' % (process_idx+1,t))
    return res

def multi_process():
    res = []
    p = multiprocessing.Pool()
    p_conn, c_conn = multiprocessing.Pipe()
    params = []
    t0 = time.time()

    # total_flts = len(train_data.groupby(by=train_group_col).size())
    _njobs = multiprocessing.cpu_count()
    ## ---- 根据cpu的进程数分组
    _flight_group_list = []
    for i in range(_njobs):
        _flight_group_list.append([])
    i =0
    for keys,flt in train_data.groupby(by=train_group_col):
        _flight_group_list[i%_njobs].append((keys,flt))
        i += 1

    for i in range(_njobs):
        args = (_flight_group_list[i],i, c_conn,t0)
        params.append(args)

    ## ---- 运行多线程
    res = p.map(fun, params)
    p.close()
    p.join()

    print('output:')
    while p_conn.poll():
        print(p_conn.recv())
    
    ## ---- 汇总运行完的数据
    param_dict = {}
    for _res in res:  # 对于每一个进程得到的结果
        for (_tmp_dict,X_train_df,y_train_df) in _res:
            param_dict[_tmp_dict['keys']] = {'intercept': _tmp_dict['intercept'], 'coef':_tmp_dict['coef']}
    print(param_dict)

```
